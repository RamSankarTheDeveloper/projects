{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d71e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.6.0.66-cp36-abi3-win_amd64.whl (42.5 MB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in d:\\anaconda\\lib\\site-packages (from opencv-contrib-python) (1.21.5)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9daed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04bb316",
   "metadata": {},
   "source": [
    "### Reading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f864fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('Cat.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2556004c",
   "metadata": {},
   "source": [
    "cv2.IMREAD_COLOR- To load a color image neglecting existing transparency (default flag)\n",
    "\n",
    "cv2.IMREAD_GRAYSCALE- To load a grayscale image\n",
    "\n",
    "cv2.IMREAD_UNCHANGED- To load an image including an alpha channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d096d0a",
   "metadata": {},
   "source": [
    "### Displaying Images in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3d2ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa9a3a",
   "metadata": {},
   "source": [
    "### Saving image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf0e63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image written sucess? :  True\n"
     ]
    }
   ],
   "source": [
    "# save image  \n",
    "#status = cv2.imwrite(r'D:\\softroniics\\Data science\\Computer vision\\dog.jpeg',img) \n",
    "#status = cv2.imwrite('dog2.jpeg',img) \n",
    "print(\"Image written sucess? : \", status) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3b94d",
   "metadata": {},
   "source": [
    "# What is a pixel?\n",
    "\n",
    "All images consist of pixels which are the raw building blocks of images. Images are made of pixels in a grid. A 640 x 480 image has 640 columns (the width) and 480 rows (the height). There are 640 * 480 = 307200 pixels in an image with those dimensions.\n",
    "\n",
    "Each pixel in a grayscale image has a value representing the shade of gray. In OpenCV, there are 256 shades of gray — from 0 to 255. So a grayscale image would have a grayscale value associated with each pixel.\n",
    "\n",
    "Pixels in a color image have additional information. There are several color spaces. For simplicity let’s only consider the RGB color space.\n",
    "\n",
    "In OpenCV color images in the RGB (Red, Green, Blue) color space have a 3-tuple associated with each pixel: (B, G, R) .\n",
    "\n",
    "\n",
    "Each value in the BGR 3-tuple has a range of [0, 255] . How many color possibilities are there for each pixel in an RGB image in OpenCV? That’s easy: 256 * 256 * 256 = 16777216 .\n",
    "\n",
    "### Vector images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f066f6",
   "metadata": {},
   "source": [
    "### Converting image to greyscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e7d0f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray Image\", imgGray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875e2cc",
   "metadata": {},
   "source": [
    "### Edge detection\n",
    "\n",
    "Edge detection is an image processing technique used for finding the boundaries of objects within images. Here we will use a popular edge detection algorithm Canny Edge Detection, developed by John F. Canny. In OpenCV, we have Canny() method to implement this algorithm. Here is the syntax:\n",
    "\n",
    "\n",
    "edges = cv2.Canny(img, minVal, maxVal, apertureSize, L2gradient)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e192e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgCanny = cv2.Canny(img, 150, 200)\n",
    "cv2.imshow(\"Canny Image\", imgCanny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a1c21",
   "metadata": {},
   "source": [
    "### Croping image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe8074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 250, 350\n",
    "point1 = np.float32([[111, 219], [287, 188], [154, 482], [352, 440]])\n",
    "point2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "matrix = cv2.getPerspectiveTransform(point1, point2)\n",
    "cropped = cv2.warpPerspective(img, matrix, (width, height))\n",
    "\n",
    "#cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"Output\", cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc9529",
   "metadata": {},
   "source": [
    "### Access Image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5801190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 1200, 3)\n",
      "Height = 1199,  Width = 1200\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "\n",
    "# Extracting the height and width of an image\n",
    "h, w = img.shape[:2]\n",
    "# Displaying the height and width\n",
    "print(\"Height = {},  Width = {}\".format(h, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "009d67ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4316400\n"
     ]
    }
   ],
   "source": [
    "print( img.size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76c9a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print( img.dtype )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e19672",
   "metadata": {},
   "source": [
    "### Extracting the RGB values of a pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cae2cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R = 236, G = 230, B = 214\n",
      "B = 214\n",
      "G = 230\n",
      "R = 236\n"
     ]
    }
   ],
   "source": [
    "# Extracting RGB values. \n",
    "# Here we have randomly chosen a pixel\n",
    "# by passing in 100, 100 for height and width.\n",
    "(B, G, R) = img[100, 100]\n",
    "  \n",
    "# Displaying the pixel values\n",
    "print(\"R = {}, G = {}, B = {}\".format(R, G, B))\n",
    "  \n",
    "# We can also pass the channel to extract \n",
    "# the value for a specific channel\n",
    "B = img[100, 100, 0]\n",
    "print(\"B = {}\".format(B))\n",
    "G = img[100, 100,1]\n",
    "print(\"G = {}\".format(G))\n",
    "R = img[100, 100, 2]\n",
    "print(\"R = {}\".format(R))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29fa72",
   "metadata": {},
   "source": [
    "### Access pixel values and modify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca98aaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[214 230 236]\n"
     ]
    }
   ],
   "source": [
    "px = img[100,100]\n",
    "print( px )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8465d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "# accessing only blue pixel\n",
    "blue = img[100,100,0]\n",
    "print( blue )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30dd5c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255, 255, 255]\n"
     ]
    }
   ],
   "source": [
    "# To modify the values, we just need to access the pixel and then overwrite it with a value\n",
    "\n",
    "px = [255,255,255]\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cbc7a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "img[100,100]=px\n",
    "newpx=img[100,100]\n",
    "print(newpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59544d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75754cc8",
   "metadata": {},
   "source": [
    "### Extracting the Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfec4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will calculate the region of interest \n",
    "# by slicing the pixels of the image\n",
    "roi = img[100 : 500, 200 : 700]\n",
    "\n",
    "cv2.imshow('image',roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c1988",
   "metadata": {},
   "source": [
    "### Resizing the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82409b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize() function takes 2 parameters,\n",
    "# the image and the dimensions\n",
    "resize = cv2.resize(img, (800, 800))\n",
    "\n",
    "cv2.imshow('image',resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ce93a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1199, 1200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e777eec8",
   "metadata": {},
   "source": [
    "The problem with this approach is that the aspect ratio of the image is not maintained. So we need to do some extra work in order to maintain a proper aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "685dd613",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=1199\n",
    "h=1200\n",
    "# Calculating the ratio\n",
    "ratio = 800 / w\n",
    "\n",
    "# Creating a tuple containing width and height\n",
    "dim = (800, int(h * ratio))\n",
    "\n",
    "# Resizing the image\n",
    "resize_aspect = cv2.resize(img, dim)\n",
    "\n",
    "cv2.imshow('image',resize_aspect)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb49891",
   "metadata": {},
   "source": [
    "### Rotating the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b343211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the center of the image\n",
    "center = (w // 2, h // 2)\n",
    "\n",
    "# Generating a rotation matrix\n",
    "matrix = cv2.getRotationMatrix2D(center, -45, 1.0)\n",
    "\n",
    "# Performing the affine transformation\n",
    "rotated = cv2.warpAffine(img, matrix, (w, h))\n",
    "\n",
    "cv2.imshow('image',rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e338f",
   "metadata": {},
   "source": [
    "### Drawing a Rectangle\n",
    "\n",
    "It takes in 5 arguments –\n",
    "\n",
    ". Image\n",
    "\n",
    ". Top-left corner co-ordinates\n",
    "\n",
    ". Bottom-right corner co-ordinates\n",
    "\n",
    ". Color (in BGR format)\n",
    "\n",
    ". Line width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9e296da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are copying the original image,\n",
    "# as it is an in-place operation.\n",
    "output = img.copy()\n",
    "\n",
    "# Using the rectangle() function to create a rectangle.\n",
    "rectangle = cv2.rectangle(output, (1000, 850),(200, 200), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('image',rectangle)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b20b4e",
   "metadata": {},
   "source": [
    "### Drawing circle\n",
    "\n",
    "cv2.circle(image, center_coordinates, radius, color, thickness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1d1916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = img.copy()\n",
    "\n",
    "circle = cv2.circle(output,(600,500), 400, (255,0,0), 2)  \n",
    "cv2.imshow('image',circle)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a58bf5",
   "metadata": {},
   "source": [
    "### Drawing Polylines\n",
    "\n",
    "cv2.polyLine(image, arr, is_closed, color, thickness) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff9dc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = img.copy()\n",
    "\n",
    "\n",
    "#defining points for polylines  \n",
    "pts = np.array([[100,50],[200,300],[700,200],[500,100]], np.int32)  \n",
    "# pts = pts.reshape((-1,1,2))  \n",
    "poly = cv2.polylines(output, [pts], True, (0,255,255), 3)  \n",
    "cv2.imshow('image',poly)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d5ed6a",
   "metadata": {},
   "source": [
    "### Displaying text\n",
    "\n",
    "It is also an in-place operation.It takes in 7 arguments –\n",
    "\n",
    "    .Image\n",
    "    .Text to be displayed\n",
    "    .Bottom-left corner co-ordinates, from where the text should start\n",
    "    .Font\n",
    "    .Font size\n",
    "    .Color (BGR format)\n",
    "    .Line width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "584f57c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the original image\n",
    "output = img.copy()\n",
    "\n",
    "# Adding the text using putText() function\n",
    "text = cv2.putText(output, 'OpenCV Demo', (100, 550), cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('image',output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749406e9",
   "metadata": {},
   "source": [
    "### Thresholding\n",
    "\n",
    "Image thresholding is an important intermediary step for image processing pipelines. Thresholding can help us to remove lighter or darker regions and contours of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2bc6f02",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6108\\837684655.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimgGray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# threshold the image by setting all pixel values less than 225\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# to 255 (white; foreground) and all pixel values >= 225 to 255\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# (black; background), thereby segmenting the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# threshold the image by setting all pixel values less than 225\n",
    "# to 255 (white; foreground) and all pixel values >= 225 to 255\n",
    "# (black; background), thereby segmenting the image\n",
    "thresh = cv2.threshold(imgGray, 225, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925025a3",
   "metadata": {},
   "source": [
    "### PLAYING VIDEO USING VIDEOCAPTURE() FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d49a67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Create a VideoCapture object and read from input file\n",
    "cap = cv2.VideoCapture('bunny.mp4')\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False):\n",
    "\tprint(\"Error opening video file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "\t\n",
    "# Capture frame-by-frame\n",
    "\tret, frame = cap.read()\n",
    "\tif ret == True:\n",
    "\t# Display the resulting frame\n",
    "\t\tcv2.imshow('Frame', frame)\n",
    "\t\t\n",
    "\t# Press Q on keyboard to exit\n",
    "\t\tif cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "\t\t\tbreak\n",
    "\n",
    "# Break the loop\n",
    "\telse:\n",
    "\t\tbreak\n",
    "# When everything done, release\n",
    "# the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac7091",
   "metadata": {},
   "source": [
    "## Capture Video from Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c6dc908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened() == False): \n",
    "  print(\"Unable to read camera feed\")\n",
    " \n",
    "while(True):\n",
    "  ret, frame = cap.read() \n",
    "  if ret == True: \n",
    "    # Display the resulting frame    \n",
    "    cv2.imshow('frame',frame) \n",
    "    # Press Q on keyboard to stop recording\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break \n",
    "  # Break the loop\n",
    "  else:\n",
    "    break \n",
    "    \n",
    "#When everything done, release the video capture and video write objects\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a936ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766df46f",
   "metadata": {},
   "source": [
    "## Saving a Video\n",
    "\n",
    "The cv2.imwrite() function is used to save the video into the file. First, we need to create a VideoWriter object. Then we should specify the FourCC code and the number of frames per second (fps). The frame size should be passed within the function.\n",
    "\n",
    "FourCC is a 4-byte code used to identify the video codec. The example is given below for saving the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c50097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import cv2  \n",
    "  \n",
    "cap = cv2.VideoCapture(0)    \n",
    "# Define the codec and create VideoWriter object  \n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  \n",
    "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (640,480))  \n",
    "  \n",
    "while(cap.isOpened()):  \n",
    "    ret, frame = cap.read()  \n",
    "    if ret==True:  \n",
    "        # write the flipped frame  \n",
    "        out.write(frame)  \n",
    "  \n",
    "        cv2.imshow('frame',frame)  \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  \n",
    "            break  \n",
    "    else:  \n",
    "        break  \n",
    "\n",
    "# Release everything if job is finished  \n",
    "cap.release()  \n",
    "out.release()  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b1bbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened() == False): \n",
    "  print(\"Unable to read camera feed\")\n",
    " \n",
    "# Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "# We convert the resolutions from float to integer.\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    " \n",
    "# Define the codec and create VideoWriter object.The output is stored in 'outpy.avi' file.\n",
    "out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    " \n",
    "while(True):\n",
    "  ret, frame = cap.read()\n",
    " \n",
    "  if ret == True: \n",
    "     \n",
    "    # Write the frame into the file 'output.avi'\n",
    "    #out.write(frame)\n",
    " \n",
    "    # Display the resulting frame    \n",
    "    cv2.imshow('frame',frame)\n",
    " \n",
    "    # Press Q on keyboard to stop recording\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break\n",
    " \n",
    "  # Break the loop\n",
    "  else:\n",
    "    break \n",
    " \n",
    "# When everything done, release the video capture and video write objects\n",
    "cap.release()\n",
    "out.release()\n",
    " \n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
