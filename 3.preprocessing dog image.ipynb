{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812bff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c451ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83cd8cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('family dogs.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9b7c2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 64, 109,  76],\n",
       "        [ 66, 111,  78],\n",
       "        [ 68, 113,  80],\n",
       "        ...,\n",
       "        [ 66, 115,  65],\n",
       "        [ 62, 113,  63],\n",
       "        [ 61, 112,  62]],\n",
       "\n",
       "       [[ 67, 112,  79],\n",
       "        [ 67, 112,  79],\n",
       "        [ 67, 112,  79],\n",
       "        ...,\n",
       "        [ 66, 115,  65],\n",
       "        [ 64, 113,  63],\n",
       "        [ 60, 111,  61]],\n",
       "\n",
       "       [[ 68, 113,  80],\n",
       "        [ 67, 112,  79],\n",
       "        [ 65, 110,  77],\n",
       "        ...,\n",
       "        [ 66, 115,  65],\n",
       "        [ 63, 112,  62],\n",
       "        [ 60, 109,  59]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  4,   2,   8],\n",
       "        [  5,   3,   9],\n",
       "        [  6,   4,  10],\n",
       "        ...,\n",
       "        [ 46,  65,  46],\n",
       "        [ 43,  65,  46],\n",
       "        [ 42,  67,  47]],\n",
       "\n",
       "       [[  1,   3,   3],\n",
       "        [  1,   3,   4],\n",
       "        [  4,   3,   7],\n",
       "        ...,\n",
       "        [ 35,  51,  33],\n",
       "        [ 34,  54,  35],\n",
       "        [ 37,  60,  38]],\n",
       "\n",
       "       [[  0,   1,   0],\n",
       "        [  0,   1,   1],\n",
       "        [  1,   0,   4],\n",
       "        ...,\n",
       "        [ 26,  40,  22],\n",
       "        [ 27,  46,  25],\n",
       "        [ 35,  56,  34]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b01c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show image\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4eceb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image written status: True\n"
     ]
    }
   ],
   "source": [
    "#save img\n",
    "status=cv2.imwrite(r'saved img of family dogs2.jpg',img)\n",
    "\n",
    "print(\"image written status:\",status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "099a6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to grey img\n",
    "greyimg=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Gray image',greyimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20fae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge detection using canny edge detection algorithm\n",
    "imgcanny=cv2.Canny(img,150,200)\n",
    "cv2.imshow('image',imgcanny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f03e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cropping image\n",
    "width,height= 250,350\n",
    "point1=np.float32([[111,219],[287,188],[154,482],[352,440]])\n",
    "point2=np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "matrix=cv2.getPerspectiveTransform(point1,point2)\n",
    "cropped = cv2.warpPerspective(img,matrix,(width,height))\n",
    "\n",
    "cv2.imshow('cropped image',cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b538aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1280, 3)\n",
      "height=1024, width=1280\n"
     ]
    }
   ],
   "source": [
    "#access image properties\n",
    "print(img.shape)\n",
    "\n",
    "#extracting the height and width of an image\n",
    "h,w = img.shape[:2]\n",
    "#displaying the height and width\n",
    "print(\"height={}, width={}\".format(h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fff0235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3932160\n"
     ]
    }
   ],
   "source": [
    "print(img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4c18612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66df2a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=21,b=31,g=23\n"
     ]
    }
   ],
   "source": [
    "#extrating the rgb values of a pixel\n",
    "(b,g,r)=img[100,100]\n",
    "\n",
    "print(\"r={},b={},g={}\".format(r,g,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f12bfb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting a single color value from a pixel\n",
    "r=img[100,100,1]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a02d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 31 21]\n",
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "#modify pixel value\n",
    "px=img[100,100]\n",
    "print(px)\n",
    "\n",
    "px=[255,255,255]\n",
    "img[100,100]=px\n",
    "\n",
    "px=img[100,100]\n",
    "print(px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9df900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting region of interest\n",
    "#by slicing the pixels of the image\n",
    "roi= img[100:500, 200:500]\n",
    "cv2.imshow('Gray image',roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5fcf516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#resize is window resizing\n",
    "# resize() function takes 2 parameters,\n",
    "# the image and the dimensions\n",
    "resize = cv2.resize(img, (800, 800))\n",
    "cv2.imshow('image',resize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397bae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('family dogs.jpeg')\n",
    "y=0\n",
    "x=0\n",
    "h=100\n",
    "w=200\n",
    "crop = image[y:y+h, x:x+w]\n",
    "cv2.imshow('Image', crop)\n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79137c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "img[100,100]=[255,255,255]\n",
    "print(img[100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "098389d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 35, 25], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[100,101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3401c37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img[100,102]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6dad232",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[100,101]=[255,255,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2438c6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([255, 255, 255], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[100,101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72fd9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "newimg=cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d89d875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Gray image',newimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d99e1c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 850)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c=(1000, 850),(200, 200), (255, 0, 0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79602a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# threshold the image by setting all pixel values less than 225\n",
    "# to 255 (white; foreground) and all pixel values >= 225 to 255\n",
    "# (black; background), thereby segmenting the image\n",
    "thresh = cv2.threshold(imgGray, 225, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2030f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read from input file\n",
    "#cap = cv2.VideoCapture('')\n",
    "cap = cv2.VideoCapture(0)\n",
    "#cap = cv2.VideoCapture(1)\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False):\n",
    "\tprint(\"Error opening video file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "\t\n",
    "# Capture frame-by-frame\n",
    "\tret, frame = cap.read()\n",
    "\tif ret == True:\n",
    "\n",
    "            # Our operations on the frame come here\n",
    "            # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t# Display the resulting frame\n",
    "\t\tcv2.imshow('Frame', frame)\n",
    "\t\t\n",
    "\t# Press Q on keyboard to exit\n",
    "\t\tif cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "\t\t\tbreak\n",
    "\n",
    "# Break the loop\n",
    "\telse:\n",
    "\t\tbreak\n",
    "# When everything done, release the video capture object\n",
    "cap.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11a9c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3021ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
